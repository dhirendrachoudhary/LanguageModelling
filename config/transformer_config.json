{"1":{
  "model_name":"transformer_2_layer",
  "seq_length": 50,
  "batch_size": 64,
  "embedding_dim": 256,
  "nhead": 4,
  "dim_feedforward": 512,
  "num_layers": 2,
  "dropout_rate": 0.1,
  "learning_rate": 0.0001,
  "grad_clip": 1.0,
  "epochs": 1
}
}